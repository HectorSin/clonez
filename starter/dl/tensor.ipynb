{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 0D Tensor (Scalar)\n",
    "\n",
    "scalar = tf.constant(1)\n",
    "print(scalar)\n",
    "print(tf.rank(scalar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 1D Tensor (Vector)\n",
    "vector = tf.constant([1, 2, 3])\n",
    "print(vector)\n",
    "print(tf.rank(vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 2D Tensor (Matrix)\n",
    "\n",
    "matrix = tf.constant([[1, 2], [3, 4]])\n",
    "print(matrix)\n",
    "print(tf.rank(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 3D Tensor\n",
    "tensor3d = tf.constant(\n",
    "    [\n",
    "        [\n",
    "            [1, 2], [3, 4]\n",
    "        ],\n",
    "        [\n",
    "            [5, 6], [7, 8]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "print(tensor3d)\n",
    "print(tf.rank(tensor3d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 타입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Data Type|TF type|Description|\n",
    "|---|---|---|\n",
    "|DT_FLOAT|tf.float32|32비트 부동 소수|\n",
    "|DT_DOUBLE|tf.float64|64비트 부동 소수|\n",
    "|DT_INT8|tf.int8|8비트 부호 있는 정수|\n",
    "|DT_INT16|tf.int16|16비트 부호 있는 정수|\n",
    "|DT_INT32|tf.int32|32비트 부호 있는 정수|\n",
    "|DT_INT64|tf.int64|64비트 부호 있는 정수|\n",
    "|DT_UINT8|tf.uint8|8비트 부호 없는 정수|\n",
    "|DT_STRING|tf.string|가변 길이 바이트 배열. Tensor의 각 원소는 바이트 배열.|\n",
    "|DT_BOOL|tf.bool|불리언|\n",
    "|DT_COMPLEX64|tf.complex64|2개의 32비트 부동 소수로 만든 복소수 : 실수부 + 허수부|\n",
    "|DT_COMPLEX128|tf.complex128|2개의 64비트 부동 소수로 만든 복소수 : 실수부 + 허수부|\n",
    "|DT_QINT8|tf.qint8|8비트 부호 있는 정수로 quantized Ops에서 사용|\n",
    "|DT_QINT32|tf.qint32|32비트 부호 있는 정수로 quantized Ops에서 사용|\n",
    "|DT_QUINT8|tf.quint8|8비트 부호 없는 정수로 quantized Ops에서 사용|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# default int32\n",
    "i = tf.constant(2)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# float32 \n",
    "# 실수의 경우 default float32\n",
    "f = tf.constant(2.)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'chan', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# string\n",
    "s = tf.constant(\"chan\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# type 지정\n",
    "f16 = tf.constant(2., dtype=tf.float16)\n",
    "print(f16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 타입 변환\n",
    "- tf.cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "f32 = tf.cast(f16, tf.float32)\n",
    "print(f32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 형상 변환\n",
    "- tf.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "(3, 1)\n",
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1], [2], [3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "y = tf.reshape(x, (1, 3))\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 전치\n",
    "- tf.transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(tf.transpose(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 압축\n",
    "- tf.squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(tf.squeeze(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 추가\n",
    "- tf.expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n",
      "tf.Tensor([[[1 2 3]]], shape=(1, 1, 3), dtype=int32)\n",
      "tf.Tensor([[[1 2 3]]], shape=(1, 1, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]], shape=(1, 3, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(tf.expand_dims(y, axis=0))\n",
    "print(tf.expand_dims(y, axis=1))\n",
    "print(tf.expand_dims(y, axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 분리\n",
    "- tf.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "[<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[1]], dtype=int32)>, <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>, <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[3]], dtype=int32)>]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(tf.split(x, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연결\n",
    "- tf.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [2]\n",
      " [3]], shape=(6, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(tf.concat([x, x], axis=0))\n",
    "print(tf.concat([x, x], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱싱\n",
    "- tf.gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1 2 3]\n",
      "  [1 2 3]]\n",
      "\n",
      " [[4 5 6]\n",
      "  [1 2 3]]], shape=(2, 2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[1 1]\n",
      "  [2 1]]\n",
      "\n",
      " [[4 4]\n",
      "  [5 4]]], shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor1d = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "gather_axis0 = tf.gather(params=tensor1d, indices=[(0,0), (1,0)], axis=0)\n",
    "print(gather_axis0)\n",
    "gather_axis1 = tf.gather(params=tensor1d, indices=[(0,0), (1,0)], axis=1)\n",
    "print(gather_axis1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 변환 정리\n",
    "|Function|Description|\n",
    "|---|---|\n",
    "|tf.shape|텐서의 구조 확인|\n",
    "|tf.size|텐서의 크기 확인|\n",
    "|tf.rank|텐서의 랭크 확인|\n",
    "|tf.reshape|텐서의 원소는 그대로 유지하면서 텐서의 구조 변경|\n",
    "|tf.squeeze|텐서에서 크기가 1인 차원 삭제|\n",
    "|tf.expand_dims|텐서에 차원을 추가|\n",
    "|tf.slice|텐서의 일부분 삭제|\n",
    "|tf.split|텐서를 한 차원을 기준으로 여러 개의 텐서로 분할|\n",
    "|tf.tile|한 텐서를 여러 번 중복해서 늘려 새 텐서 생성|\n",
    "|tf.concat|한 차원을 기준으로 텐서 연결|\n",
    "|tf.reverse|한 차원을 기준으로 텐서를 역전|\n",
    "|tf.transpose|텐서 전치|\n",
    "|tf.gather|주어진 인덱스에 따라 텐서의 원소를 인덱싱|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 연산\n",
    "|연산자 오버로딩|함수|연산|\n",
    "|---|---|---|\n",
    "|+|tf.add|더하기 연산|\n",
    "|-|tf.subtract|빼기 연산|\n",
    "|*|tf.multiply|곱하기 연산|\n",
    "|/|tf.divide|나누기 연산|\n",
    "|@|tf.matmul|행렬곱 연산|\n",
    "||tf.reduce_max|텐서 값 중 최대값|\n",
    "||tf.argmax|최대값의 위치 반환|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0차원 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 더하기 빼기\n",
    "print(tf.constant(1) + tf.constant(2))\n",
    "print(tf.constant(1) - tf.constant(2))\n",
    "print(tf.add(tf.constant(1), tf.constant(2)))\n",
    "print(tf.subtract(tf.constant(1), tf.constant(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0.5, shape=(), dtype=float64)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0.5, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# 곱하기 나누기\n",
    "print(tf.constant(1) * tf.constant(2))\n",
    "print(tf.constant(1) / tf.constant(2))\n",
    "print(tf.multiply(tf.constant(1), tf.constant(2)))\n",
    "print(tf.divide(tf.constant(1), tf.constant(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a int8 tensor but is a int16 tensor [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 서로 다른 타입의 경우 연산 불가능\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# InvalidArgumentError\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aiffel-research/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/aiffel-research/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a int8 tensor but is a int16 tensor [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "# 서로 다른 타입의 경우 연산 불가능\n",
    "\n",
    "# InvalidArgumentError\n",
    "tf.constant(1, dtype=tf.int8) + tf.constant(2, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int16, numpy=3>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타입 변환 필요\n",
    "tf.cast(tf.constant(1, dtype=tf.int8), dtype=tf.int16) + tf.constant(2, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1차원 이상의 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 7 9], shape=(3,), dtype=int32)\n",
      "tf.Tensor([-3 -3 -3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([ 4 10 18], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0.25 0.4  0.5 ], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3])\n",
    "b = tf.constant([4, 5, 6])\n",
    "\n",
    "print(a + b)\n",
    "print(a - b)\n",
    "print(a * b)\n",
    "print(a / b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2차원 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 4]\n",
      " [6 8]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0]\n",
      " [0 0]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  4]\n",
      " [ 9 16]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 7 10]\n",
      " [15 22]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],[3, 4]])\n",
    "b = tf.constant([[1, 2],[3, 4]])\n",
    "\n",
    "print(a + b)\n",
    "print(a - b)\n",
    "print(a * b)\n",
    "print(a @ b)\n",
    "print(a / b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor([4 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2 4], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# reduce_max\n",
    "matrix = tf.constant([[1, 2], [4, 3]])\n",
    "print(tf.reduce_max(matrix, axis=None))\n",
    "print(tf.reduce_max(matrix, axis=0))\n",
    "print(tf.reduce_max(matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# argmax\n",
    "matrix = tf.constant([[1, 2], [4, 3]])\n",
    "print(tf.argmax(matrix, axis=None))\n",
    "print(tf.argmax(matrix, axis=0))\n",
    "print(tf.argmax(matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.26894143 0.7310586 ]\n",
      " [0.98201376 0.01798621]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.00247262 0.26894143]\n",
      " [0.9975274  0.7310586 ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.26894143 0.7310586 ]\n",
      " [0.98201376 0.01798621]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor([0.98201376 0.01798621], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "\n",
    "# softmax 연산에 허용되는 타입은 [half, bfloat16, float, double]\n",
    "matrix = tf.constant([[1, 2], [4, 3]])\n",
    "# InvalidArgumentError \n",
    "\n",
    "matrix = tf.constant([[1, 2], [7, 3]], dtype=tf.float32)\n",
    "print(tf.nn.softmax(matrix, axis=None))\n",
    "print(tf.nn.softmax(matrix, axis=0))\n",
    "print(tf.nn.softmax(matrix, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
